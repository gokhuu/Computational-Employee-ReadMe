{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ef4195-9a95-4a95-a1b0-fd06301956fd",
   "metadata": {},
   "source": [
    "# Multi Classification Neural Network\n",
    "\n",
    "Create a Neural Network to classify Control, 15q duplication, and 16p11 deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb1aa78d-ce2b-4dd8-9d1d-3da9a09d33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c43f65e-7cef-4f02-a623-050d7c2b9f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autism</th>\n",
       "      <th>CDK5RAP1</th>\n",
       "      <th>TMEM246</th>\n",
       "      <th>PKD1</th>\n",
       "      <th>EDEM1</th>\n",
       "      <th>LSM11</th>\n",
       "      <th>COL26A1</th>\n",
       "      <th>CPSF6</th>\n",
       "      <th>DCTN5</th>\n",
       "      <th>MRPS33</th>\n",
       "      <th>...</th>\n",
       "      <th>UBE2T</th>\n",
       "      <th>PTK7</th>\n",
       "      <th>EIF2B3</th>\n",
       "      <th>CDK16</th>\n",
       "      <th>C15orf61</th>\n",
       "      <th>GSTP1</th>\n",
       "      <th>IPP</th>\n",
       "      <th>ASB3</th>\n",
       "      <th>EHD4</th>\n",
       "      <th>NRSN2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PGP1-1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.561823</td>\n",
       "      <td>9.167399</td>\n",
       "      <td>4.762467</td>\n",
       "      <td>4.259699</td>\n",
       "      <td>3.333153</td>\n",
       "      <td>5.245319</td>\n",
       "      <td>15.288924</td>\n",
       "      <td>10.670947</td>\n",
       "      <td>15.418737</td>\n",
       "      <td>...</td>\n",
       "      <td>36.320081</td>\n",
       "      <td>23.422699</td>\n",
       "      <td>6.506580</td>\n",
       "      <td>7.639236</td>\n",
       "      <td>1.808342</td>\n",
       "      <td>253.147425</td>\n",
       "      <td>2.624415</td>\n",
       "      <td>5.473228</td>\n",
       "      <td>9.892221</td>\n",
       "      <td>14.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGP1-2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.050032</td>\n",
       "      <td>6.121957</td>\n",
       "      <td>3.086031</td>\n",
       "      <td>3.888580</td>\n",
       "      <td>3.064389</td>\n",
       "      <td>4.530108</td>\n",
       "      <td>14.225061</td>\n",
       "      <td>11.109630</td>\n",
       "      <td>21.596005</td>\n",
       "      <td>...</td>\n",
       "      <td>19.707959</td>\n",
       "      <td>12.679506</td>\n",
       "      <td>6.687741</td>\n",
       "      <td>7.457054</td>\n",
       "      <td>1.614225</td>\n",
       "      <td>290.182382</td>\n",
       "      <td>3.276070</td>\n",
       "      <td>7.483068</td>\n",
       "      <td>7.377414</td>\n",
       "      <td>11.613564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGP1-3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.481599</td>\n",
       "      <td>14.205795</td>\n",
       "      <td>8.663784</td>\n",
       "      <td>2.988719</td>\n",
       "      <td>13.747564</td>\n",
       "      <td>6.189141</td>\n",
       "      <td>18.021990</td>\n",
       "      <td>15.850792</td>\n",
       "      <td>9.871680</td>\n",
       "      <td>...</td>\n",
       "      <td>15.002978</td>\n",
       "      <td>9.314311</td>\n",
       "      <td>6.744241</td>\n",
       "      <td>36.158595</td>\n",
       "      <td>3.626686</td>\n",
       "      <td>118.126815</td>\n",
       "      <td>2.221963</td>\n",
       "      <td>5.087976</td>\n",
       "      <td>2.392554</td>\n",
       "      <td>15.666102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM23716-1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.396121</td>\n",
       "      <td>15.263531</td>\n",
       "      <td>8.198981</td>\n",
       "      <td>3.433083</td>\n",
       "      <td>13.873706</td>\n",
       "      <td>5.018456</td>\n",
       "      <td>17.714552</td>\n",
       "      <td>15.832140</td>\n",
       "      <td>4.594193</td>\n",
       "      <td>...</td>\n",
       "      <td>13.609106</td>\n",
       "      <td>9.826147</td>\n",
       "      <td>6.570986</td>\n",
       "      <td>32.786094</td>\n",
       "      <td>3.988325</td>\n",
       "      <td>103.634970</td>\n",
       "      <td>2.459700</td>\n",
       "      <td>4.626596</td>\n",
       "      <td>2.301205</td>\n",
       "      <td>16.500382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM23716-2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.721746</td>\n",
       "      <td>14.125613</td>\n",
       "      <td>10.278191</td>\n",
       "      <td>3.331196</td>\n",
       "      <td>13.211928</td>\n",
       "      <td>5.620373</td>\n",
       "      <td>15.806883</td>\n",
       "      <td>15.434513</td>\n",
       "      <td>7.544800</td>\n",
       "      <td>...</td>\n",
       "      <td>13.346974</td>\n",
       "      <td>4.147004</td>\n",
       "      <td>5.990253</td>\n",
       "      <td>55.245293</td>\n",
       "      <td>3.849378</td>\n",
       "      <td>111.978695</td>\n",
       "      <td>2.494851</td>\n",
       "      <td>4.843815</td>\n",
       "      <td>2.285043</td>\n",
       "      <td>18.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Autism  CDK5RAP1    TMEM246       PKD1     EDEM1      LSM11  \\\n",
       "PGP1-1          0  5.561823   9.167399   4.762467  4.259699   3.333153   \n",
       "PGP1-2          0  2.050032   6.121957   3.086031  3.888580   3.064389   \n",
       "PGP1-3          0  2.481599  14.205795   8.663784  2.988719  13.747564   \n",
       "GM23716-1       0  4.396121  15.263531   8.198981  3.433083  13.873706   \n",
       "GM23716-2       0  3.721746  14.125613  10.278191  3.331196  13.211928   \n",
       "\n",
       "            COL26A1      CPSF6      DCTN5     MRPS33  ...      UBE2T  \\\n",
       "PGP1-1     5.245319  15.288924  10.670947  15.418737  ...  36.320081   \n",
       "PGP1-2     4.530108  14.225061  11.109630  21.596005  ...  19.707959   \n",
       "PGP1-3     6.189141  18.021990  15.850792   9.871680  ...  15.002978   \n",
       "GM23716-1  5.018456  17.714552  15.832140   4.594193  ...  13.609106   \n",
       "GM23716-2  5.620373  15.806883  15.434513   7.544800  ...  13.346974   \n",
       "\n",
       "                PTK7    EIF2B3      CDK16  C15orf61       GSTP1       IPP  \\\n",
       "PGP1-1     23.422699  6.506580   7.639236  1.808342  253.147425  2.624415   \n",
       "PGP1-2     12.679506  6.687741   7.457054  1.614225  290.182382  3.276070   \n",
       "PGP1-3      9.314311  6.744241  36.158595  3.626686  118.126815  2.221963   \n",
       "GM23716-1   9.826147  6.570986  32.786094  3.988325  103.634970  2.459700   \n",
       "GM23716-2   4.147004  5.990253  55.245293  3.849378  111.978695  2.494851   \n",
       "\n",
       "               ASB3      EHD4      NRSN2  \n",
       "PGP1-1     5.473228  9.892221  14.017985  \n",
       "PGP1-2     7.483068  7.377414  11.613564  \n",
       "PGP1-3     5.087976  2.392554  15.666102  \n",
       "GM23716-1  4.626596  2.301205  16.500382  \n",
       "GM23716-2  4.843815  2.285043  18.534124  \n",
       "\n",
       "[5 rows x 11301 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('Organoid Files/all_autism_fpkm_T_multi_class.csv', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e65bebf-8fe4-45fa-a541-56025185eac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 11300)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define target/features\n",
    "\n",
    "y = df.Autism\n",
    "x = df.iloc[:,1:]\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1213ee9c-91b3-422b-92ef-5dcf630d7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#create early stop\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss',patience=10, verbose=1)\n",
    "\n",
    "#create model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=10000, activation='sigmoid',input_shape=[11300]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=7500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=5000, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=2500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=1000, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=750, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=250, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=100, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=75, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=50, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=25, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "#compile model with functions\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='poisson',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0681e8e6-b22b-4919-8142-6d483a63d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 6s 1s/step - loss: 1.3141 - accuracy: 0.2095\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2914 - accuracy: 0.3700\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1941 - accuracy: 0.3714\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1401 - accuracy: 0.3581\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9603 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9250 - accuracy: 0.4510\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0711 - accuracy: 0.3886\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9502 - accuracy: 0.3952\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0383 - accuracy: 0.3767\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9106 - accuracy: 0.4829\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9152 - accuracy: 0.4562\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9468 - accuracy: 0.4629\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9361 - accuracy: 0.4814\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7997 - accuracy: 0.4748\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8556 - accuracy: 0.4629\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8749 - accuracy: 0.5424\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8804 - accuracy: 0.4881\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0277 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7614 - accuracy: 0.5252\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0397 - accuracy: 0.4510\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0156 - accuracy: 0.4933\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8557 - accuracy: 0.4376\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8216 - accuracy: 0.4933\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7429 - accuracy: 0.5238\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8563 - accuracy: 0.5133\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8106 - accuracy: 0.5252\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8628 - accuracy: 0.4933\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7582 - accuracy: 0.5490\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7487 - accuracy: 0.5186\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6996 - accuracy: 0.5743\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7714 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7659 - accuracy: 0.5133\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9037 - accuracy: 0.5690\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9305 - accuracy: 0.5200\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0116 - accuracy: 0.4576\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9386 - accuracy: 0.4695\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8473 - accuracy: 0.5252\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8271 - accuracy: 0.5186\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7441 - accuracy: 0.5371\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7161 - accuracy: 0.5438\n",
      "Epoch 00040: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9005 - accuracy: 0.4035\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.9602 - accuracy: 0.4386\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3933 - accuracy: 0.2982\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9519 - accuracy: 0.4035\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9197 - accuracy: 0.4035\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9384 - accuracy: 0.4386\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9702 - accuracy: 0.3684\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9142 - accuracy: 0.4035\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9286 - accuracy: 0.4035\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9577 - accuracy: 0.4386\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8429 - accuracy: 0.4912\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9465 - accuracy: 0.4386\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8384 - accuracy: 0.4737\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8132 - accuracy: 0.4912\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8233 - accuracy: 0.4912\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7888 - accuracy: 0.4912\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7955 - accuracy: 0.4737\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8680 - accuracy: 0.4561\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8735 - accuracy: 0.4737\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7754 - accuracy: 0.4912\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8205 - accuracy: 0.5439\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7489 - accuracy: 0.5439\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8265 - accuracy: 0.5439\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8773 - accuracy: 0.4912\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8728 - accuracy: 0.4561\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8748 - accuracy: 0.4912\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9169 - accuracy: 0.3860\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9171 - accuracy: 0.4386\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9165 - accuracy: 0.4035\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9067 - accuracy: 0.4561\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8891 - accuracy: 0.4211\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8470 - accuracy: 0.4561\n",
      "Epoch 00032: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6906 - accuracy: 0.4561\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7489 - accuracy: 0.4737\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7325 - accuracy: 0.4211\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7849 - accuracy: 0.5088\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6444 - accuracy: 0.5263\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5739 - accuracy: 0.5614\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6024 - accuracy: 0.5088\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5890 - accuracy: 0.5614\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8374 - accuracy: 0.4561\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7457 - accuracy: 0.4211\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7311 - accuracy: 0.3509\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7473 - accuracy: 0.3684\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6817 - accuracy: 0.4386\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6344 - accuracy: 0.4737\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5956 - accuracy: 0.5263\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5921 - accuracy: 0.5088\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5864 - accuracy: 0.5439\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7804 - accuracy: 0.5439\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6764 - accuracy: 0.5263\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6305 - accuracy: 0.5789\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6831 - accuracy: 0.4386\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6693 - accuracy: 0.5263\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6159 - accuracy: 0.5965\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6034 - accuracy: 0.5614\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7844 - accuracy: 0.4211\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6582 - accuracy: 0.4386\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6836 - accuracy: 0.4386\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6369 - accuracy: 0.5789\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6005 - accuracy: 0.6316\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6092 - accuracy: 0.6491\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6219 - accuracy: 0.5965\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5571 - accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5226 - accuracy: 0.7193\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5302 - accuracy: 0.7193\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5499 - accuracy: 0.7018\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 2s/step - loss: 0.5515 - accuracy: 0.6842\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5292 - accuracy: 0.7018\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5997 - accuracy: 0.7018\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5165 - accuracy: 0.7368\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5090 - accuracy: 0.7368\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5335 - accuracy: 0.6842\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5041 - accuracy: 0.7368\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4903 - accuracy: 0.7544\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5663 - accuracy: 0.7018\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5183 - accuracy: 0.7368\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5102 - accuracy: 0.7368\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6737 - accuracy: 0.7018\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5912 - accuracy: 0.6842\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5749 - accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5261 - accuracy: 0.7368\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5681 - accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5482 - accuracy: 0.6842\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5226 - accuracy: 0.7193\n",
      "Epoch 00026: early stopping\n",
      "Accuracy of each fold = [0.0, 0.07142857142857142, 0.5, 0.35714285714285715, 0.0]\n",
      "Avg accuracy = 0.18571428571428572\n"
     ]
    }
   ],
   "source": [
    "#import cross fold validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k = 5 #number of folds\n",
    "\n",
    "#initialize kfold\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "#create empty list to hold scores\n",
    "acc_score = []\n",
    "\n",
    "#split training data\n",
    "for train_index,test_index in kf.split(x):\n",
    "    x_train, x_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #fit model with training data\n",
    "    model.fit(x_train, y_train, batch_size = 50, epochs=200, shuffle=True, callbacks=[early_stop])\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    #record accuracy of each fold\n",
    "    acc = accuracy_score(pred.round(), y_test)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "#Print accuracy of the model\n",
    "avg_score = sum(acc_score)/k\n",
    "print('Accuracy of each fold = {}'.format(acc_score))\n",
    "print('Avg accuracy = {}'.format(avg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0736f2-11fd-4f45-8923-351df7844acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
