{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ef4195-9a95-4a95-a1b0-fd06301956fd",
   "metadata": {},
   "source": [
    "# Multi Classification Neural Network\n",
    "\n",
    "Create a Neural Network to classify Control, 15q duplication, and 16p11 deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb1aa78d-ce2b-4dd8-9d1d-3da9a09d33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c43f65e-7cef-4f02-a623-050d7c2b9f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Autism</th>\n",
       "      <th>CDK5RAP1</th>\n",
       "      <th>TMEM246</th>\n",
       "      <th>PKD1</th>\n",
       "      <th>EDEM1</th>\n",
       "      <th>LSM11</th>\n",
       "      <th>COL26A1</th>\n",
       "      <th>CPSF6</th>\n",
       "      <th>DCTN5</th>\n",
       "      <th>MRPS33</th>\n",
       "      <th>...</th>\n",
       "      <th>UBE2T</th>\n",
       "      <th>PTK7</th>\n",
       "      <th>EIF2B3</th>\n",
       "      <th>CDK16</th>\n",
       "      <th>C15orf61</th>\n",
       "      <th>GSTP1</th>\n",
       "      <th>IPP</th>\n",
       "      <th>ASB3</th>\n",
       "      <th>EHD4</th>\n",
       "      <th>NRSN2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PGP1-1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.561823</td>\n",
       "      <td>9.167399</td>\n",
       "      <td>4.762467</td>\n",
       "      <td>4.259699</td>\n",
       "      <td>3.333153</td>\n",
       "      <td>5.245319</td>\n",
       "      <td>15.288924</td>\n",
       "      <td>10.670947</td>\n",
       "      <td>15.418737</td>\n",
       "      <td>...</td>\n",
       "      <td>36.320081</td>\n",
       "      <td>23.422699</td>\n",
       "      <td>6.506580</td>\n",
       "      <td>7.639236</td>\n",
       "      <td>1.808342</td>\n",
       "      <td>253.147425</td>\n",
       "      <td>2.624415</td>\n",
       "      <td>5.473228</td>\n",
       "      <td>9.892221</td>\n",
       "      <td>14.017985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGP1-2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.050032</td>\n",
       "      <td>6.121957</td>\n",
       "      <td>3.086031</td>\n",
       "      <td>3.888580</td>\n",
       "      <td>3.064389</td>\n",
       "      <td>4.530108</td>\n",
       "      <td>14.225061</td>\n",
       "      <td>11.109630</td>\n",
       "      <td>21.596005</td>\n",
       "      <td>...</td>\n",
       "      <td>19.707959</td>\n",
       "      <td>12.679506</td>\n",
       "      <td>6.687741</td>\n",
       "      <td>7.457054</td>\n",
       "      <td>1.614225</td>\n",
       "      <td>290.182382</td>\n",
       "      <td>3.276070</td>\n",
       "      <td>7.483068</td>\n",
       "      <td>7.377414</td>\n",
       "      <td>11.613564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGP1-3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.481599</td>\n",
       "      <td>14.205795</td>\n",
       "      <td>8.663784</td>\n",
       "      <td>2.988719</td>\n",
       "      <td>13.747564</td>\n",
       "      <td>6.189141</td>\n",
       "      <td>18.021990</td>\n",
       "      <td>15.850792</td>\n",
       "      <td>9.871680</td>\n",
       "      <td>...</td>\n",
       "      <td>15.002978</td>\n",
       "      <td>9.314311</td>\n",
       "      <td>6.744241</td>\n",
       "      <td>36.158595</td>\n",
       "      <td>3.626686</td>\n",
       "      <td>118.126815</td>\n",
       "      <td>2.221963</td>\n",
       "      <td>5.087976</td>\n",
       "      <td>2.392554</td>\n",
       "      <td>15.666102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM23716-1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.396121</td>\n",
       "      <td>15.263531</td>\n",
       "      <td>8.198981</td>\n",
       "      <td>3.433083</td>\n",
       "      <td>13.873706</td>\n",
       "      <td>5.018456</td>\n",
       "      <td>17.714552</td>\n",
       "      <td>15.832140</td>\n",
       "      <td>4.594193</td>\n",
       "      <td>...</td>\n",
       "      <td>13.609106</td>\n",
       "      <td>9.826147</td>\n",
       "      <td>6.570986</td>\n",
       "      <td>32.786094</td>\n",
       "      <td>3.988325</td>\n",
       "      <td>103.634970</td>\n",
       "      <td>2.459700</td>\n",
       "      <td>4.626596</td>\n",
       "      <td>2.301205</td>\n",
       "      <td>16.500382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM23716-2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.721746</td>\n",
       "      <td>14.125613</td>\n",
       "      <td>10.278191</td>\n",
       "      <td>3.331196</td>\n",
       "      <td>13.211928</td>\n",
       "      <td>5.620373</td>\n",
       "      <td>15.806883</td>\n",
       "      <td>15.434513</td>\n",
       "      <td>7.544800</td>\n",
       "      <td>...</td>\n",
       "      <td>13.346974</td>\n",
       "      <td>4.147004</td>\n",
       "      <td>5.990253</td>\n",
       "      <td>55.245293</td>\n",
       "      <td>3.849378</td>\n",
       "      <td>111.978695</td>\n",
       "      <td>2.494851</td>\n",
       "      <td>4.843815</td>\n",
       "      <td>2.285043</td>\n",
       "      <td>18.534124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Autism  CDK5RAP1    TMEM246       PKD1     EDEM1      LSM11  \\\n",
       "PGP1-1          0  5.561823   9.167399   4.762467  4.259699   3.333153   \n",
       "PGP1-2          0  2.050032   6.121957   3.086031  3.888580   3.064389   \n",
       "PGP1-3          0  2.481599  14.205795   8.663784  2.988719  13.747564   \n",
       "GM23716-1       0  4.396121  15.263531   8.198981  3.433083  13.873706   \n",
       "GM23716-2       0  3.721746  14.125613  10.278191  3.331196  13.211928   \n",
       "\n",
       "            COL26A1      CPSF6      DCTN5     MRPS33  ...      UBE2T  \\\n",
       "PGP1-1     5.245319  15.288924  10.670947  15.418737  ...  36.320081   \n",
       "PGP1-2     4.530108  14.225061  11.109630  21.596005  ...  19.707959   \n",
       "PGP1-3     6.189141  18.021990  15.850792   9.871680  ...  15.002978   \n",
       "GM23716-1  5.018456  17.714552  15.832140   4.594193  ...  13.609106   \n",
       "GM23716-2  5.620373  15.806883  15.434513   7.544800  ...  13.346974   \n",
       "\n",
       "                PTK7    EIF2B3      CDK16  C15orf61       GSTP1       IPP  \\\n",
       "PGP1-1     23.422699  6.506580   7.639236  1.808342  253.147425  2.624415   \n",
       "PGP1-2     12.679506  6.687741   7.457054  1.614225  290.182382  3.276070   \n",
       "PGP1-3      9.314311  6.744241  36.158595  3.626686  118.126815  2.221963   \n",
       "GM23716-1   9.826147  6.570986  32.786094  3.988325  103.634970  2.459700   \n",
       "GM23716-2   4.147004  5.990253  55.245293  3.849378  111.978695  2.494851   \n",
       "\n",
       "               ASB3      EHD4      NRSN2  \n",
       "PGP1-1     5.473228  9.892221  14.017985  \n",
       "PGP1-2     7.483068  7.377414  11.613564  \n",
       "PGP1-3     5.087976  2.392554  15.666102  \n",
       "GM23716-1  4.626596  2.301205  16.500382  \n",
       "GM23716-2  4.843815  2.285043  18.534124  \n",
       "\n",
       "[5 rows x 11301 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('Organoid Files/all_autism_fpkm_T_multi_class.csv', header=0, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e65bebf-8fe4-45fa-a541-56025185eac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 11300)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define target/features\n",
    "\n",
    "y = df.Autism\n",
    "x = df.iloc[:,1:]\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1213ee9c-91b3-422b-92ef-5dcf630d7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#create early stop\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss',patience=10, verbose=1)\n",
    "\n",
    "#create model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=10000, activation='sigmoid',input_shape=[11300]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=7500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=5000, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=2500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=1000, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=750, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=500, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=250, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=100, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=75, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=50, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=25, activation='sigmoid'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "#compile model with functions\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='poisson',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0681e8e6-b22b-4919-8142-6d483a63d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 6s 1s/step - loss: 1.5936 - accuracy: 0.3819\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2774 - accuracy: 0.3395\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3138 - accuracy: 0.3343\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3326 - accuracy: 0.3024\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2430 - accuracy: 0.2533\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2358 - accuracy: 0.2348\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1906 - accuracy: 0.3090\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.3243 - accuracy: 0.3276\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2490 - accuracy: 0.3024\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1611 - accuracy: 0.3276\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1652 - accuracy: 0.3529\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2041 - accuracy: 0.3648\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1873 - accuracy: 0.2786\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2143 - accuracy: 0.3581\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2153 - accuracy: 0.2771\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1350 - accuracy: 0.3714\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1285 - accuracy: 0.4695\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1532 - accuracy: 0.3024\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1491 - accuracy: 0.4271\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1833 - accuracy: 0.3276\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1770 - accuracy: 0.3143\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2076 - accuracy: 0.3952\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2132 - accuracy: 0.4071\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1485 - accuracy: 0.2971\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1540 - accuracy: 0.3833\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2424 - accuracy: 0.3024\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1204 - accuracy: 0.3090\n",
      "Epoch 00027: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1571 - accuracy: 0.3684\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0964 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1661 - accuracy: 0.3509\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1835 - accuracy: 0.2807\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0824 - accuracy: 0.2807\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1298 - accuracy: 0.3860\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1584 - accuracy: 0.2281\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1514 - accuracy: 0.2807\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1076 - accuracy: 0.2807\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1235 - accuracy: 0.2632\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1029 - accuracy: 0.1930\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0645 - accuracy: 0.3684\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1170 - accuracy: 0.2807\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0537 - accuracy: 0.3684\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1178 - accuracy: 0.3158\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.2146 - accuracy: 0.2456\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0967 - accuracy: 0.2982\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1332 - accuracy: 0.2982\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1419 - accuracy: 0.3333\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9978 - accuracy: 0.3333\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0102 - accuracy: 0.3684\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0715 - accuracy: 0.2982\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1312 - accuracy: 0.2807\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1389 - accuracy: 0.3333\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0439 - accuracy: 0.2982\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1129 - accuracy: 0.3509\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1911 - accuracy: 0.2632\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1349 - accuracy: 0.2632\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.1374 - accuracy: 0.2807\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0949 - accuracy: 0.3158\n",
      "Epoch 00030: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0949 - accuracy: 0.2105\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9661 - accuracy: 0.2807\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9889 - accuracy: 0.3158\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0286 - accuracy: 0.1930\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0845 - accuracy: 0.2281\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0207 - accuracy: 0.3158\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9365 - accuracy: 0.3509\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9696 - accuracy: 0.2982\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9209 - accuracy: 0.3158\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9884 - accuracy: 0.3860\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8846 - accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9432 - accuracy: 0.3684\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9877 - accuracy: 0.3333\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0386 - accuracy: 0.2807\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9777 - accuracy: 0.3158\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9265 - accuracy: 0.3860\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9497 - accuracy: 0.3684\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8938 - accuracy: 0.3333\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8740 - accuracy: 0.3684\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8884 - accuracy: 0.3684\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8592 - accuracy: 0.4035\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8910 - accuracy: 0.3509\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 1.0049 - accuracy: 0.3333\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9534 - accuracy: 0.3509\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9724 - accuracy: 0.2807\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8737 - accuracy: 0.4035\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9011 - accuracy: 0.3684\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9084 - accuracy: 0.3333\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9144 - accuracy: 0.4211\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8846 - accuracy: 0.3333\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.8834 - accuracy: 0.3860\n",
      "Epoch 00031: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7604 - accuracy: 0.4211\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7830 - accuracy: 0.4035\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7241 - accuracy: 0.4386\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7772 - accuracy: 0.3509\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7547 - accuracy: 0.4211\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7438 - accuracy: 0.4386\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7323 - accuracy: 0.4561\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7679 - accuracy: 0.4211\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7301 - accuracy: 0.4386\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6901 - accuracy: 0.5088\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6793 - accuracy: 0.5088\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7154 - accuracy: 0.4737\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7406 - accuracy: 0.4386\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7410 - accuracy: 0.4035\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7618 - accuracy: 0.3509\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7123 - accuracy: 0.4386\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6747 - accuracy: 0.4561\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6814 - accuracy: 0.5088\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6487 - accuracy: 0.5789\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6573 - accuracy: 0.5088\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5996 - accuracy: 0.6316\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6172 - accuracy: 0.5614\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7065 - accuracy: 0.5965\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6574 - accuracy: 0.5789\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6216 - accuracy: 0.5789\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6426 - accuracy: 0.5789\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6078 - accuracy: 0.5789\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6121 - accuracy: 0.6491\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6300 - accuracy: 0.5965\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5681 - accuracy: 0.6316\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5761 - accuracy: 0.6316\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6831 - accuracy: 0.5965\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5772 - accuracy: 0.6140\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5729 - accuracy: 0.6491\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6536 - accuracy: 0.6140\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5949 - accuracy: 0.6316\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5694 - accuracy: 0.6140\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5603 - accuracy: 0.6140\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6344 - accuracy: 0.5263\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5933 - accuracy: 0.6316\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5829 - accuracy: 0.5965\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5600 - accuracy: 0.6140\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5495 - accuracy: 0.6140\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5250 - accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5130 - accuracy: 0.7018\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5165 - accuracy: 0.6842\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5327 - accuracy: 0.6491\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7233 - accuracy: 0.5439\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5631 - accuracy: 0.5965\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5110 - accuracy: 0.6491\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5130 - accuracy: 0.6667\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4993 - accuracy: 0.6842\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5961 - accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5068 - accuracy: 0.6842\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5479 - accuracy: 0.6842\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5774 - accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5187 - accuracy: 0.7018\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5501 - accuracy: 0.6140\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6230 - accuracy: 0.5965\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6042 - accuracy: 0.6491\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5241 - accuracy: 0.6667\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5128 - accuracy: 0.6842\n",
      "Epoch 00062: early stopping\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6463 - accuracy: 0.6140\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5620 - accuracy: 0.6667\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5576 - accuracy: 0.7368\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5147 - accuracy: 0.7368\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5294 - accuracy: 0.7544\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4945 - accuracy: 0.7719\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4764 - accuracy: 0.7719\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5166 - accuracy: 0.7719\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5142 - accuracy: 0.7719\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5877 - accuracy: 0.7018\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5826 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5448 - accuracy: 0.6842\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5550 - accuracy: 0.6842\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5321 - accuracy: 0.7018\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4768 - accuracy: 0.7719\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5558 - accuracy: 0.7193\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6077 - accuracy: 0.6491\n",
      "Epoch 00017: early stopping\n",
      "Accuracy of each fold = [0.0, 0.0, 0.5, 0.14285714285714285, 0.0]\n",
      "Avg accuracy = 0.12857142857142856\n"
     ]
    }
   ],
   "source": [
    "#import cross fold validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "k = 5 #number of folds\n",
    "\n",
    "#initialize kfold\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "#create empty list to hold scores\n",
    "acc_score = []\n",
    "\n",
    "#split training data\n",
    "for train_index,test_index in kf.split(x):\n",
    "    x_train, x_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #fit model with training data\n",
    "    model.fit(x_train, y_train, batch_size = 50, epochs=200, shuffle=True, callbacks=[early_stop])\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    #record accuracy of each fold\n",
    "    acc = accuracy_score(pred.round(), y_test)\n",
    "    acc_score.append(acc)\n",
    "\n",
    "#Print accuracy of the model\n",
    "avg_score = sum(acc_score)/k\n",
    "print('Accuracy of each fold = {}'.format(acc_score))\n",
    "print('Avg accuracy = {}'.format(avg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0736f2-11fd-4f45-8923-351df7844acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
