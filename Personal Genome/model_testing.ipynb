{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Autism  CDK5RAP1    TMEM246       PKD1     EDEM1      LSM11  \\\n",
      "PGP1-1          0  5.561823   9.167399   4.762467  4.259699   3.333153   \n",
      "PGP1-2          0  2.050032   6.121957   3.086031  3.888580   3.064389   \n",
      "PGP1-3          0  2.481599  14.205795   8.663784  2.988719  13.747564   \n",
      "GM23716-1       0  4.396121  15.263531   8.198981  3.433083  13.873706   \n",
      "GM23716-2       0  3.721746  14.125613  10.278191  3.331196  13.211928   \n",
      "\n",
      "            COL26A1      CPSF6      DCTN5     MRPS33  ...      UBE2T  \\\n",
      "PGP1-1     5.245319  15.288924  10.670947  15.418737  ...  36.320081   \n",
      "PGP1-2     4.530108  14.225061  11.109630  21.596005  ...  19.707959   \n",
      "PGP1-3     6.189141  18.021990  15.850792   9.871680  ...  15.002978   \n",
      "GM23716-1  5.018456  17.714552  15.832140   4.594193  ...  13.609106   \n",
      "GM23716-2  5.620373  15.806883  15.434513   7.544800  ...  13.346974   \n",
      "\n",
      "                PTK7    EIF2B3      CDK16  C15orf61       GSTP1       IPP  \\\n",
      "PGP1-1     23.422699  6.506580   7.639236  1.808342  253.147425  2.624415   \n",
      "PGP1-2     12.679506  6.687741   7.457054  1.614225  290.182382  3.276070   \n",
      "PGP1-3      9.314311  6.744241  36.158595  3.626686  118.126815  2.221963   \n",
      "GM23716-1   9.826147  6.570986  32.786094  3.988325  103.634970  2.459700   \n",
      "GM23716-2   4.147004  5.990253  55.245293  3.849378  111.978695  2.494851   \n",
      "\n",
      "               ASB3      EHD4      NRSN2  \n",
      "PGP1-1     5.473228  9.892221  14.017985  \n",
      "PGP1-2     7.483068  7.377414  11.613564  \n",
      "PGP1-3     5.087976  2.392554  15.666102  \n",
      "GM23716-1  4.626596  2.301205  16.500382  \n",
      "GM23716-2  4.843815  2.285043  18.534124  \n",
      "\n",
      "[5 rows x 11272 columns]\n"
     ]
    }
   ],
   "source": [
    "#import raw data\n",
    "df = pd.read_csv('Organoid Files/all_autism_fpkm_t_threshold.csv', header=0, index_col=0)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGP1-1        0\n",
      "PGP1-2        0\n",
      "PGP1-3        0\n",
      "GM23716-1     0\n",
      "GM23716-2     0\n",
      "             ..\n",
      "14781x16-1    1\n",
      "14781x16-2    1\n",
      "14781x16-3    1\n",
      "14746x8-1     1\n",
      "14746x8-2     1\n",
      "Name: Autism, Length: 71, dtype: int64\n",
      "            CDK5RAP1    TMEM246       PKD1     EDEM1      LSM11   COL26A1  \\\n",
      "PGP1-1      5.561823   9.167399   4.762467  4.259699   3.333153  5.245319   \n",
      "PGP1-2      2.050032   6.121957   3.086031  3.888580   3.064389  4.530108   \n",
      "PGP1-3      2.481599  14.205795   8.663784  2.988719  13.747564  6.189141   \n",
      "GM23716-1   4.396121  15.263531   8.198981  3.433083  13.873706  5.018456   \n",
      "GM23716-2   3.721746  14.125613  10.278191  3.331196  13.211928  5.620373   \n",
      "...              ...        ...        ...       ...        ...       ...   \n",
      "14781x16-1  6.384259   7.771520   7.071175  3.297171   5.224131  4.838935   \n",
      "14781x16-2  3.128289   8.186893   9.025883  4.009783   4.728078  6.729686   \n",
      "14781x16-3  7.880060   4.857521   7.076191  4.097137   5.166222  5.299588   \n",
      "14746x8-1   3.388043   3.334954  10.996357  1.545692   1.109277  6.404090   \n",
      "14746x8-2   3.623195   6.834265   3.154569  3.818004   3.262106  4.399106   \n",
      "\n",
      "                CPSF6      DCTN5     MRPS33      COPS8  ...      UBE2T  \\\n",
      "PGP1-1      15.288924  10.670947  15.418737  26.492518  ...  36.320081   \n",
      "PGP1-2      14.225061  11.109630  21.596005  23.446239  ...  19.707959   \n",
      "PGP1-3      18.021990  15.850792   9.871680  32.272768  ...  15.002978   \n",
      "GM23716-1   17.714552  15.832140   4.594193  30.869273  ...  13.609106   \n",
      "GM23716-2   15.806883  15.434513   7.544800  24.221830  ...  13.346974   \n",
      "...               ...        ...        ...        ...  ...        ...   \n",
      "14781x16-1  16.391965  13.168677   9.170113  23.544437  ...  23.827240   \n",
      "14781x16-2  13.232519  10.730565   5.805684  18.649314  ...  15.109922   \n",
      "14781x16-3  21.528132  11.529954  13.647595  22.095454  ...  24.614361   \n",
      "14746x8-1    4.283906   2.709484   7.187927   9.226015  ...  35.300336   \n",
      "14746x8-2   15.213019  10.777413  18.043668  23.712450  ...  25.649829   \n",
      "\n",
      "                 PTK7    EIF2B3      CDK16  C15orf61       GSTP1       IPP  \\\n",
      "PGP1-1      23.422699  6.506580   7.639236  1.808342  253.147425  2.624415   \n",
      "PGP1-2      12.679506  6.687741   7.457054  1.614225  290.182382  3.276070   \n",
      "PGP1-3       9.314311  6.744241  36.158595  3.626686  118.126815  2.221963   \n",
      "GM23716-1    9.826147  6.570986  32.786094  3.988325  103.634970  2.459700   \n",
      "GM23716-2    4.147004  5.990253  55.245293  3.849378  111.978695  2.494851   \n",
      "...               ...       ...        ...       ...         ...       ...   \n",
      "14781x16-1  11.225659  8.583395  16.807080  2.247722  115.635692  1.998373   \n",
      "14781x16-2   6.428226  6.306627  18.606929  2.320908   93.281158  2.860871   \n",
      "14781x16-3   9.036573  6.284167  25.226473  2.000993  180.321536  3.957021   \n",
      "14746x8-1   11.964774  2.285754  44.006054  2.186490  356.445464  1.027271   \n",
      "14746x8-2   23.876904  5.690446  10.509333  2.133355  275.675347  2.857793   \n",
      "\n",
      "                ASB3      EHD4      NRSN2  \n",
      "PGP1-1      5.473228  9.892221  14.017985  \n",
      "PGP1-2      7.483068  7.377414  11.613564  \n",
      "PGP1-3      5.087976  2.392554  15.666102  \n",
      "GM23716-1   4.626596  2.301205  16.500382  \n",
      "GM23716-2   4.843815  2.285043  18.534124  \n",
      "...              ...       ...        ...  \n",
      "14781x16-1  4.476631  2.150457  14.543974  \n",
      "14781x16-2  2.771161  2.254990  10.858082  \n",
      "14781x16-3  5.646545  2.751370  12.931406  \n",
      "14746x8-1   1.624070  2.718903  17.184158  \n",
      "14746x8-2   6.195983  8.082016  11.506148  \n",
      "\n",
      "[71 rows x 11271 columns]\n"
     ]
    }
   ],
   "source": [
    "#create target and dataset\n",
    "y = df.Autism\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 11271)\n",
      "(53,)\n",
      "(18, 11271)\n"
     ]
    }
   ],
   "source": [
    "#create test and train data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, random_state=1)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#raw data\n",
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(train_X, train_y)\n",
    "logreg_pred  = logreg.predict(test_X) \n",
    "acc_log = round(logreg.score(train_X, train_y)*100,2)\n",
    "print(acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.7\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "svc = SVC()\n",
    "svc.fit(train_X,train_y)\n",
    "svc_pred = svc.predict(test_X)\n",
    "acc_svc = round(svc.score(train_X,train_y,)*100,2)\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(train_X, train_y)\n",
    "rf_pred = random_forest.predict(test_X)\n",
    "rf_acc = round(random_forest.score(train_X, train_y)*100,2)\n",
    "print(rf_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.79\n"
     ]
    }
   ],
   "source": [
    "#K Nearest Neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_X, train_y)\n",
    "knn_pred = knn.predict(test_X)\n",
    "acc_knn = round(knn.score(train_X, train_y) * 100,2)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train_X, train_y)\n",
    "g_pred = gaussian.predict(test_X)\n",
    "acc_gauss = round(gaussian.score(train_X, train_y)*100,2)\n",
    "print(acc_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X,train_y)\n",
    "p_pred = round(perceptron.score(train_X, train_y)*100,2)\n",
    "print(p_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC(max_iter=1000000)\n",
    "linear_svc.fit(train_X, train_y)\n",
    "lsvc = linear_svc.predict(test_X)\n",
    "linear_acc = round(linear_svc.score(train_X, train_y)*100,2)\n",
    "print(linear_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train_X, train_y)\n",
    "sgd_pred = sgd.predict(test_X)\n",
    "sgd_acc = round(sgd.score(train_X, train_y)*100,2)\n",
    "print(sgd_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_X, train_y)\n",
    "dt_pred = dt.predict(test_X)\n",
    "dt_acc = round(dt.score(train_X, train_y)*100,2)\n",
    "print(dt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.6858 - accuracy: 0.4528\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6947 - accuracy: 0.5094\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7027 - accuracy: 0.4528\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6954 - accuracy: 0.4528\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7115 - accuracy: 0.5094\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6679 - accuracy: 0.6604\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6783 - accuracy: 0.5283\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6755 - accuracy: 0.5849\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6834 - accuracy: 0.5660\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6948 - accuracy: 0.5472\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6997 - accuracy: 0.4528\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6900 - accuracy: 0.5472\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7146 - accuracy: 0.3962\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7102 - accuracy: 0.3774\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6853 - accuracy: 0.5094\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6949 - accuracy: 0.5094\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6724 - accuracy: 0.5660\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6908 - accuracy: 0.5283\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6712 - accuracy: 0.6981\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6831 - accuracy: 0.6038\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6547 - accuracy: 0.6981\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6856 - accuracy: 0.5283\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6571 - accuracy: 0.7547\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6607 - accuracy: 0.6981\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6939 - accuracy: 0.4906\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6885 - accuracy: 0.5283\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6663 - accuracy: 0.5472\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6596 - accuracy: 0.6792\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6464 - accuracy: 0.7170\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6457 - accuracy: 0.6604\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6346 - accuracy: 0.7358\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6542 - accuracy: 0.6226\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6273 - accuracy: 0.7736\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6485 - accuracy: 0.6226\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6128 - accuracy: 0.8302\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6185 - accuracy: 0.8113\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6463 - accuracy: 0.6415\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6226 - accuracy: 0.7170\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6166 - accuracy: 0.7925\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5992 - accuracy: 0.7170\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6398 - accuracy: 0.6792\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6070 - accuracy: 0.7170\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6074 - accuracy: 0.7358\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6061 - accuracy: 0.7925\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5785 - accuracy: 0.8302\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5834 - accuracy: 0.8113\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5653 - accuracy: 0.8491\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5827 - accuracy: 0.7925\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5622 - accuracy: 0.8113\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6049 - accuracy: 0.7358\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5719 - accuracy: 0.7925\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5478 - accuracy: 0.8302\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5585 - accuracy: 0.7925\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5613 - accuracy: 0.8302\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5597 - accuracy: 0.8113\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5336 - accuracy: 0.8113\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5190 - accuracy: 0.9057\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5380 - accuracy: 0.8302\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5009 - accuracy: 0.8868\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5092 - accuracy: 0.8868\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5055 - accuracy: 0.8679\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5193 - accuracy: 0.8302\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4843 - accuracy: 0.8679\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4767 - accuracy: 0.8679\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4841 - accuracy: 0.8868\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4748 - accuracy: 0.8868\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4973 - accuracy: 0.8491\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4783 - accuracy: 0.8679\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4461 - accuracy: 0.8868\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4414 - accuracy: 0.8679\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4454 - accuracy: 0.9245\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4225 - accuracy: 0.8679\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4333 - accuracy: 0.9245\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4148 - accuracy: 0.9245\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4645 - accuracy: 0.8302\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4238 - accuracy: 0.9057\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4022 - accuracy: 0.9623\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3751 - accuracy: 0.9434\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3730 - accuracy: 0.9623\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4052 - accuracy: 0.9057\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.4001 - accuracy: 0.9245\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3666 - accuracy: 0.9245\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3752 - accuracy: 0.9245\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.3714 - accuracy: 0.9434\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.3743 - accuracy: 0.9245\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3328 - accuracy: 0.9434\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3027 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3285 - accuracy: 0.9434\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3163 - accuracy: 0.9623\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3174 - accuracy: 0.9434\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3172 - accuracy: 0.9434\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3127 - accuracy: 0.9811\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2897 - accuracy: 0.9811\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2739 - accuracy: 0.9623\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2918 - accuracy: 0.9811\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2867 - accuracy: 0.9623\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2696 - accuracy: 0.9811\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2610 - accuracy: 0.9811\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2672 - accuracy: 0.9811\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2490 - accuracy: 0.9811\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002D946296A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 220ms/step - loss: 1.3608 - accuracy: 0.6226\n",
      "[1.3607946634292603, 0.6226415038108826]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "clf = keras.Sequential([\n",
    "    layers.Dense(units=10000, activation='relu',kernel_initializer='random_normal',input_shape=[11271]),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=7000, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=5000, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=2000, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=1000,activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=700, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=500,activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=200, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=100,activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=70, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=50,activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=20, activation='relu',kernel_initializer='random_normal'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(units=1,activation='sigmoid',kernel_initializer='random_normal')\n",
    "])\n",
    "\n",
    "clf.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "clf.fit(train_X,train_y,batch_size=500,epochs = 100)\n",
    "print((clf.evaluate(train_X,train_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
